{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiF1wpAu1wq0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import librosa\n",
        "import librosa.display\n",
        "from skimage.transform import resize\n",
        "import IPython.display as ipd\n",
        "import cv2\n",
        "from PIL import Image, ImageChops\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWsZ3psYO9NH",
        "outputId": "a11b7706-445a-42ea-b09c-e87ff1a31f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64-BLZWt0wnR",
        "outputId": "51f51ffe-1657-4c04-c5ab-d091b323f02a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1scuFwqh8s7KIYAfZW1Eu6088ZAK2SI-v\n",
            "To: /content/Emotional Speech Dataset (ESD).zip\n",
            "100% 2.45G/2.45G [00:27<00:00, 87.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1scuFwqh8s7KIYAfZW1Eu6088ZAK2SI-v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIpmKKCJ1j1i"
      },
      "outputs": [],
      "source": [
        "!unzip 'Emotional Speech Dataset (ESD).zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trim(im):\n",
        "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
        "    diff = ImageChops.difference(im, bg)\n",
        "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        return im.crop(bbox)"
      ],
      "metadata": {
        "id": "114UFqfRHVaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpeFRwDZAhWE"
      },
      "outputs": [],
      "source": [
        "class Language_dataset:\n",
        "  def __init__(self, language,root_directory):\n",
        "    self.language = language\n",
        "    self.root_directory = root_directory\n",
        "    self.Categories = ['Angry','Happy','Neutral','Sad','Surprise']\n",
        "\n",
        "  all_files = {'Angry':[],\n",
        "               'Happy':[],\n",
        "               'Neutral':[],\n",
        "               'Sad' :[],\n",
        "               'Surprise':[]\n",
        "               }\n",
        "\n",
        "  def define_categories(self):\n",
        "\n",
        "    list_dir = os.listdir(self.root_directory)\n",
        "    for dir in list_dir:\n",
        "      if '00' not in dir:# Remove all of the redundant files\n",
        "        list_dir.remove(dir)\n",
        "    list_dir.sort()\n",
        "    if self.language == 'Chinese':\n",
        "      self.list_dir = list_dir[0:10]\n",
        "    elif self.language == 'English':\n",
        "      self.list_dir = list_dir[10:]\n",
        "\n",
        "  def define_wav_files(self):\n",
        "    self.define_categories()\n",
        "    for dir in self.list_dir:\n",
        "      for category in self.Categories:\n",
        "        category_path = os.path.join(self.root_directory,dir,category)\n",
        "        files_of_category = os.listdir(category_path)\n",
        "        for files in files_of_category:\n",
        "          full_path = os.path.join(category_path,files)\n",
        "          self.all_files[category].append(full_path)\n",
        "\n",
        "  def dataset_split():\n",
        "    pass\n",
        "\n",
        "  def make_directory(self,directory='Spectogram'):\n",
        "    print(directory)\n",
        "    if not os.path.exists(directory):\n",
        "      os.makedirs(directory,exist_ok=True)\n",
        "    language_dir = os.path.join(directory,self.language)\n",
        "\n",
        "    if os.path.exists(language_dir):\n",
        "      shutil.rmtree(language_dir)\n",
        "    os.mkdir(language_dir)\n",
        "    for category in self.Categories:\n",
        "      os.mkdir(os.path.join(directory,self.language,category))\n",
        "\n",
        "  def save_spectogram(self,directory='Spectogram'):\n",
        "    self.make_directory(directory)\n",
        "    for category in self.all_files:\n",
        "      c = 0\n",
        "      for wav_file in self.all_files[category]:\n",
        "        print(c,category)\n",
        "        x, sr = librosa.load(wav_file, sr=44100)#44100\n",
        "        plt.figure(figsize=(10,10))\n",
        "        src_ft = librosa.stft(x)\n",
        "        src_db = librosa.amplitude_to_db(abs(src_ft))\n",
        "        librosa.display.specshow(src_db, sr=sr)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        file_name = wav_file.split('/')[3][:-4]\n",
        "        spec_path = os.path.join(directory, self.language, category,file_name + '.jpg')\n",
        "        plt.savefig(spec_path)\n",
        "        c = c + 1\n",
        "        if c >= 70:\n",
        "          break\n",
        "\n",
        "  def save_numpy_array(self,directory='Numpyarray'):\n",
        "    self.make_directory(directory)\n",
        "    for category in self.all_files:\n",
        "      for wav_file in self.all_files[category]:\n",
        "        try:\n",
        "          x, sr = librosa.load(wav_file, sr=44100)#44100\n",
        "          src_ft = librosa.stft(x)\n",
        "          file_name = wav_file.split('/')[3][:-4]\n",
        "          spec_path = os.path.join(directory, self.language, category,file_name + '.npy')\n",
        "          np.save(spec_path,src_ft)\n",
        "        except:\n",
        "          print(wav_file)\n",
        "  def crop(self,directory):\n",
        "    for category in self.all_files:\n",
        "      image_files = os.listdir(os.path.join(directory, self.language, category))\n",
        "      for image_file in image_files:\n",
        "          print(image_file)\n",
        "          spec_path = os.path.join(directory, self.language, category, image_file)\n",
        "          img = Image.open(spec_path)\n",
        "          croped = trim(img)\n",
        "          croped.save(spec_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -1 '/content/drive/MyDrive/Numpyarray/English/Sad' | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c13uODOURtQ",
        "outputId": "015346c4-426e-4c8c-d653-836b9e4fb0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGvEp3jPIC48"
      },
      "outputs": [],
      "source": [
        "English = Language_dataset(language='English', root_directory='Emotion Speech Dataset')\n",
        "English.define_wav_files()\n",
        "English.save_numpy_array('/content/drive/MyDrive/Numpyarray')\n",
        "English.save_spectogram('/content/drive/MyDrive/Spectogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7suSQK1J057Q"
      },
      "outputs": [],
      "source": [
        "Chinese = Language_dataset(language='Chinese', root_directory='Emotion Speech Dataset')\n",
        "Chinese.define_wav_files()\n",
        "Chinese.save_numpy_array('/content/drive/MyDrive/Numpyarray')\n",
        "Chinese.save_spectogram('/content/drive/MyDrive/Spectogram')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9VTLciS9NIU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}